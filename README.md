# MLD: Motion Latent Diffusion Models

### [Executing your Commands via Motion Diffusion in Latent Space](https://chenxin.tech/mld)
### [Project Page](https://chenxin.tech/mld) | [Paper](https://github.com/ChenFengYe/motion-latent-diffusion/blob/main/MLD_Arxiv.pdf) | [Arxiv](https://chenxin.tech/mld)
Motion Latent Diffusion (MLD) is a **text-to-motion** and **action-to-motion** diffusion model. Our work ahieves **state-of-the-art** motion quality and two orders of magnitude **faster** than previous diffusion models on raw motion data.

## üö© News
8/12/22 - Upload paper and init projectÔºåcode will be released in two weeks

## ‚ö° Quick Start

## ‚ñ∂Ô∏è Demo

## üíª Train your own models

### Datasets

### Evaluations

## üëÄ Visualization

## BibTex

## Acknowledgments

## License
This code is distributed under an [MIT LICENSE](LICENSE).

Note that our code depends on other libraries, including SMPL, SMPL-X, PyTorch3D, and uses datasets which each have their own respective licenses that must also be followed.
